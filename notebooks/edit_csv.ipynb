{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a602b4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/Users/campshelor/Desktop/GitHub Repos/miros')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19fc5641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b7edbe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Austria\n",
      "Belgium\n",
      "Canada\n",
      "Germany\n",
      "Denmark\n",
      "Spain\n",
      "Finland\n",
      "France\n",
      "Italy\n",
      "Netherlands\n",
      "Norway\n",
      "Portugal\n",
      "Sweden\n",
      "Switzerland\n",
      "United Kingdom\n",
      "USA\n"
     ]
    }
   ],
   "source": [
    "df[\"Country\"] = df[\"Country\"].str.replace(\"AT\", \"Austria\", regex=False)\n",
    "df[\"Country\"] = df[\"Country\"].str.replace(\"DE\", \"Germany\", regex=False)\n",
    "df[\"Country\"] = df[\"Country\"].str.replace(\"ES\", \"Spain\", regex=False)\n",
    "df[\"Country\"] = df[\"Country\"].str.replace(\"FI\", \"Finland\", regex=False)\n",
    "df[\"Country\"] = df[\"Country\"].str.replace(\"DK\", \"Denmark\", regex=False)\n",
    "df[\"Country\"] = df[\"Country\"].str.replace(\"IT\", \"Italy\", regex=False)\n",
    "df[\"Country\"] = df[\"Country\"].str.replace(\"PT\", \"Portugal\", regex=False)\n",
    "df[\"Country\"] = df[\"Country\"].str.replace(\"SE\", \"Sweden\", regex=False)\n",
    "df[\"Country\"] = df[\"Country\"].str.replace(\"FR\", \"France\", regex=False)\n",
    "df[\"Country\"] = df[\"Country\"].str.replace(\"US\", \"USA\", regex=False)\n",
    "df[\"Country\"] = df[\"Country\"].str.replace(\"USAAA\", \"USA\", regex=False)\n",
    "df[\"Country\"] = df[\"Country\"].str.replace(\"USAA\", \"USA\", regex=False)\n",
    "df[\"Country\"] = df[\"Country\"].str.replace(\"UK\", \"United Kingdom\", regex=False)\n",
    "\n",
    "\n",
    "for v in df[\"Country\"].unique():\n",
    "    print(v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0abb8826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "systematic musicology; music cognition; empirical musicology\n",
      "music information retrieval; audio feature extraction; machine learning; genre classification; interfaces\n",
      "systematic musicology; musicology; acoustics/psychoacoustics (unit focus)\n",
      "machine learning for music, expressive performance, MIR, audio signal processing, recommendation\n",
      "embodied music cognition, XR, interaction, movement, psychoacoustics, performance\n",
      "live performance research; music perception & movement; hearing science; health & wellbeing; motion capture; EEG; acoustics\n",
      "melodic perception; tonality; memory for music; musical structure; amusia; aging & music\n",
      "rhythm & beat perception; timing; motor system; Parkinson’s disease; fMRI/EEG; brain stimulation; music & movement\n",
      "music & language; auditory perception; cognitive neuroscience; EEG/MEG/fMRI; amusia; rhythm & pitch\n",
      "music perception & cognition; audio/music technology; sound recording; instruments & interfaces; interaction & immersive systems; acoustics; MIR\n",
      "creative AI; musical metacreation; generative systems; interactive arts; deep learning; affective computing; multi‑agent systems\n",
      "music & health; neurologic music therapy; neurorehabilitation; rhythmic auditory stimulation; EEG/clinical research; dementia & stroke\n",
      "melodic contour; tonality; auditory illusions; perceptual & cognitive development; music perception\n",
      "music cognition & emotion; hearing science; health & wellbeing; assistive audio tech; group singing; affective responses\n",
      "room acoustics; binaural/audio communication; spatial audio; electroacoustics; audio technology\n",
      "systematic musicology; psychoacoustics; music cognition; acoustics; computational/empirical methods\n",
      "audio & acoustic signal processing; hearing/health applications; speech & noise reduction; spatial audio\n",
      "music neuroscience; perception; rhythm & timing; emotion; learning; clinical applications; brain imaging\n",
      "audio signal processing; MIR; music information retrieval; musical interfaces; computational musicology; AI & music\n",
      "audio processing; spatial sound; room acoustics & auralization; ambisonics; loudspeaker arrays\n",
      "cognitive neuroscience; music cognition; speech & language; EEG/MEG; neuroimaging; development & aging\n",
      "music psychology; music cognition; MIR; movement & rhythm; affect; neuroscience; education\n",
      "computer music; acoustics; signal processing; perception & cognition; interaction; sound synthesis; musical interfaces\n",
      "empirical aesthetics, music preference, aesthetic experience, audience research, cognitive neuroscience of music\n",
      "multimodal interaction; music & movement; interactive systems; arts & technology\n",
      "image processing; audio/speech processing; computer vision; multimedia\n",
      "computer music; sound synthesis; performance technologies; electroacoustic music\n",
      "beat perception, rhythm perception, timing, music & language, development, animal timing\n",
      "rhythm, timing, entrainment, motion capture, movement, performance, music cognition, neuroscience\n",
      "music information retrieval; HCI & interactive music; automatic music generation; music robotics; audio processing; immersive audio\n",
      "sonification; sound design; musical interfaces; performance science; emotion & gesture\n",
      "digital musicology, corpus analysis, computational music theory, harmony, musical form, music cognition\n",
      "audio engineering; psychoacoustics; spatial audio; recording & production; perceptual evaluation\n",
      "embodied interaction; audiovisual (AVUI); biosignals (EMG/BCI); HCI; machine learning for arts\n",
      "computer music; brain–computer music interfacing (BCMI); AI & music; quantum/alternative computing; digital health & assistive tech\n",
      "music cognition; neuroscience of music; education; therapy & wellbeing; performance\n",
      "acoustics; vibration; signal processing; audio engineering; hearing science; underwater acoustics; structural dynamics\n",
      "spatial & immersive audio; virtual acoustics; VR/XR; room acoustic modelling; soundscape; audio production\n",
      "music cognition, psychoacoustics, acoustics, computational modeling, music & language, performance\n",
      "music & emotion, memory, earworms, entrainment, corpus studies, imagination\n",
      "audio machine learning, MIR, music/audio analysis, intelligent instruments, interaction, spatial audio\n",
      "music cognition, auditory neuroscience, neuroimaging, absolute pitch, music & language, emotion\n",
      "robotic musicianship; music informatics; new instruments/interfaces; HCI; audio engineering & production\n",
      "computer music; new instruments/interfaces; sound synthesis; spatial audio; composition & performance tech\n",
      "hyperinstruments; AI/music; participatory/City Symphonies; vocal & performance tech; interactive opera\n",
      "music‑evoked memory; emotion; groove & entrainment; neuroimaging (fMRI/EEG); sensorimotor coupling\n",
      "MIR/audio machine learning; machine listening; urban sound (SONYC); music perception; information retrieval\n",
      "music perception/cognition; attention; repetition & expectation; emotion; interdisciplinary collaboration\n",
      "computer music; audio signal processing; sound synthesis; spatial audio; music perception/HCI\n",
      "systematic musicology; music cognition; empirical methods; corpus-based analysis; computational modeling; perception\n",
      "auditory neuroscience; brainstem/FFR; speech-in-noise; music & literacy; aging; clinical populations; EEG\n",
      "music training; development; EEG/fMRI & DWI; emotion/cognition; lifespan; education\n",
      "music‑language relations; rhythm/beat perception; cross‑species studies; neuroimaging; behavioral experiments\n",
      "music-language; rhythm/grammar; developmental; autism; genetics; EEG/fMRI; social engagement\n",
      "music information retrieval; speech/audio analysis; source separation; machine learning; music similarity; datasets\n",
      "music & speech perception; auditory selective attention; EEG; spatial audio; speech‑in‑noise\n",
      "music perception; music cognition; music theory; behavioral experiments\n",
      "auditory neuroethology; animal communication; songbirds; neural coding; electrophysiology; systems neuroscience\n",
      "music & speech perception; language and memory; auditory & visual perception; cognitive neuroscience; EEG; behavioral experiments\n",
      "media arts; electronic music; visualization; VR/immersive; spatial audio; HCI; interactive systems\n",
      "neural dynamics; rhythm/meter; entrainment; embodied/ecological cognition; group drumming; computational models; EEG\n"
     ]
    }
   ],
   "source": [
    "for v in df[\"Focus Keywords\"].unique():\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10093b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LabName</th>\n",
       "      <th>Institution</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Website</th>\n",
       "      <th>ContactPerson</th>\n",
       "      <th>ContactInfo</th>\n",
       "      <th>Specifics</th>\n",
       "      <th>Sources</th>\n",
       "      <th>Notes</th>\n",
       "      <th>__source_file</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Centre for Systematic Musicology (ZSM)</td>\n",
       "      <td>University of Graz</td>\n",
       "      <td>Graz</td>\n",
       "      <td>Austria</td>\n",
       "      <td>https://zsm.kug.ac.at/</td>\n",
       "      <td>Richard Parncutt (founder/contact)</td>\n",
       "      <td>richard.parncutt@uni-graz.at</td>\n",
       "      <td>systematic musicology; music cognition; empiri...</td>\n",
       "      <td>https://zsm.kug.ac.at/</td>\n",
       "      <td>Centre existed 2009–2023 (archival site still ...</td>\n",
       "      <td>music_research_labs_batch_2025-11-12_1333.csv</td>\n",
       "      <td>47.070868</td>\n",
       "      <td>15.438279</td>\n",
       "      <td>Computational Musicology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MIR Group @ TU Wien (Information &amp; Software En...</td>\n",
       "      <td>TU Wien</td>\n",
       "      <td>Vienna</td>\n",
       "      <td>Austria</td>\n",
       "      <td>https://www.ifs.tuwien.ac.at/mir/</td>\n",
       "      <td>Andreas Rauber (group lead); Thomas Lidy (coll...</td>\n",
       "      <td>rauber@ifs.tuwien.ac.at</td>\n",
       "      <td>music information retrieval; audio feature ext...</td>\n",
       "      <td>https://informatics.tuwien.ac.at/people/andrea...</td>\n",
       "      <td>Group within Information Systems Engineering (...</td>\n",
       "      <td>music_research_labs_batch_2025-11-12_1333.csv</td>\n",
       "      <td>48.208354</td>\n",
       "      <td>16.372504</td>\n",
       "      <td>Human–Computer Interaction (Music); Music &amp; AI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Systematic Musicology (Department of Musicology)</td>\n",
       "      <td>University of Vienna</td>\n",
       "      <td>Vienna</td>\n",
       "      <td>Austria</td>\n",
       "      <td>https://musikwissenschaft.univie.ac.at/</td>\n",
       "      <td>Michele Calella (Head); Anja‑Xiaoxing Cui (Dep...</td>\n",
       "      <td>musikwissenschaft@univie.ac.at</td>\n",
       "      <td>systematic musicology; musicology; acoustics/p...</td>\n",
       "      <td>https://ufind.univie.ac.at/en/pvz_sub.html?id=442</td>\n",
       "      <td>Systematic Musicology is one of the department...</td>\n",
       "      <td>music_research_labs_batch_2025-11-12_1333.csv</td>\n",
       "      <td>48.208354</td>\n",
       "      <td>16.372504</td>\n",
       "      <td>Audio Signal Processing; Computational Musicology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Institute of Computational Perception (ICP)</td>\n",
       "      <td>Johannes Kepler University Linz</td>\n",
       "      <td>Linz</td>\n",
       "      <td>Austria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gerhard Widmer (Head); Markus Schedl</td>\n",
       "      <td>https://www.jku.at/en/institute-of-computation...</td>\n",
       "      <td>machine learning for music, expressive perform...</td>\n",
       "      <td>https://www.jku.at/en/institute-of-computation...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>music_cognition_labs_part1.csv</td>\n",
       "      <td>48.305908</td>\n",
       "      <td>14.286198</td>\n",
       "      <td>Audio Signal Processing; Music Information Ret...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IPEM – Institute for Psychoacoustics &amp; Electro...</td>\n",
       "      <td>Ghent University</td>\n",
       "      <td>Ghent</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pieter-Jan Maes (Director &amp; Head of Research)</td>\n",
       "      <td>https://www.ugent.be/lw/kunstwetenschappen/ipe...</td>\n",
       "      <td>embodied music cognition, XR, interaction, mov...</td>\n",
       "      <td>https://www.ugent.be/lw/kunstwetenschappen/ipe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>music_cognition_labs_part1.csv</td>\n",
       "      <td>51.053829</td>\n",
       "      <td>3.725012</td>\n",
       "      <td>Auditory Cognition; Human–Computer Interaction...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Music Cognition (Eastman School of Music)</td>\n",
       "      <td>University of Rochester – Eastman School of Music</td>\n",
       "      <td>Rochester, NY</td>\n",
       "      <td>USA</td>\n",
       "      <td>https://www.esm.rochester.edu/theory/ea/music-...</td>\n",
       "      <td>David Temperley (contact for Music Cognition)</td>\n",
       "      <td>temperley@esm.rochester.edu</td>\n",
       "      <td>music perception; music cognition; music theor...</td>\n",
       "      <td>https://www.esm.rochester.edu/theory/ea/music-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Batch__US_Labs__Vanderbilt___Eastman_.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Music Perception</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Gentner Lab (Auditory Neuroscience)</td>\n",
       "      <td>University of California, San Diego</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>USA</td>\n",
       "      <td>https://gentnerlab.ucsd.edu/</td>\n",
       "      <td>Timothy Q. Gentner (PI)</td>\n",
       "      <td>tgentner@ucsd.edu; Phone: +1 858‑822‑6763; McG...</td>\n",
       "      <td>auditory neuroethology; animal communication; ...</td>\n",
       "      <td>https://gentnerlab.ucsd.edu/; https://psycholo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Batch__US_Labs__Vanderbilt___Eastman_.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cognitive Neuroscience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>LAMP Lab – Language &amp; Music Perception</td>\n",
       "      <td>University of San Diego</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>USA</td>\n",
       "      <td>https://www.lamp-lab.org/</td>\n",
       "      <td>Laura K. Getz (Director)</td>\n",
       "      <td>usdlamplab@gmail.com; lgetz@sandiego.edu</td>\n",
       "      <td>music &amp; speech perception; language and memory...</td>\n",
       "      <td>https://www.lamp-lab.org/; https://www.sandieg...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>music_cognition_research_batch_CAN_US.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cognitive Neuroscience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Media Arts &amp; Technology (MAT) Program (incl. A...</td>\n",
       "      <td>University of California, Santa Barbara</td>\n",
       "      <td>Santa Barbara, CA</td>\n",
       "      <td>USA</td>\n",
       "      <td>http://www.mat.ucsb.edu/</td>\n",
       "      <td>Program faculty include JoAnn Kuchera‑Morin (A...</td>\n",
       "      <td>MAT program: info@mat.ucsb.edu; Address: 3309 ...</td>\n",
       "      <td>media arts; electronic music; visualization; V...</td>\n",
       "      <td>https://www.mat.ucsb.edu/mad/; https://www.gra...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Batch__US_Labs__Vanderbilt___Eastman_.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Audio Signal Processing; Human–Computer Intera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Music Dynamics Lab</td>\n",
       "      <td>University of Connecticut</td>\n",
       "      <td>Storrs, CT</td>\n",
       "      <td>USA</td>\n",
       "      <td>https://musicdynamicslab.uconn.edu/</td>\n",
       "      <td>Edward W. Large; Ji Chul Kim; staff and studen...</td>\n",
       "      <td>See lab site; affiliated EEG lab: https://csse...</td>\n",
       "      <td>neural dynamics; rhythm/meter; entrainment; em...</td>\n",
       "      <td>https://musicdynamicslab.uconn.edu/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Batch__US_Labs__Vanderbilt___Eastman_.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cognitive Neuroscience</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              LabName  \\\n",
       "0              Centre for Systematic Musicology (ZSM)   \n",
       "1   MIR Group @ TU Wien (Information & Software En...   \n",
       "2    Systematic Musicology (Department of Musicology)   \n",
       "3         Institute of Computational Perception (ICP)   \n",
       "4   IPEM – Institute for Psychoacoustics & Electro...   \n",
       "..                                                ...   \n",
       "56          Music Cognition (Eastman School of Music)   \n",
       "57                Gentner Lab (Auditory Neuroscience)   \n",
       "58             LAMP Lab – Language & Music Perception   \n",
       "59  Media Arts & Technology (MAT) Program (incl. A...   \n",
       "60                                 Music Dynamics Lab   \n",
       "\n",
       "                                          Institution               City  \\\n",
       "0                                  University of Graz               Graz   \n",
       "1                                             TU Wien             Vienna   \n",
       "2                                University of Vienna             Vienna   \n",
       "3                     Johannes Kepler University Linz               Linz   \n",
       "4                                    Ghent University              Ghent   \n",
       "..                                                ...                ...   \n",
       "56  University of Rochester – Eastman School of Music      Rochester, NY   \n",
       "57                University of California, San Diego      San Diego, CA   \n",
       "58                            University of San Diego      San Diego, CA   \n",
       "59            University of California, Santa Barbara  Santa Barbara, CA   \n",
       "60                          University of Connecticut         Storrs, CT   \n",
       "\n",
       "    Country                                            Website  \\\n",
       "0   Austria                             https://zsm.kug.ac.at/   \n",
       "1   Austria                  https://www.ifs.tuwien.ac.at/mir/   \n",
       "2   Austria            https://musikwissenschaft.univie.ac.at/   \n",
       "3   Austria                                                NaN   \n",
       "4   Belgium                                                NaN   \n",
       "..      ...                                                ...   \n",
       "56      USA  https://www.esm.rochester.edu/theory/ea/music-...   \n",
       "57      USA                       https://gentnerlab.ucsd.edu/   \n",
       "58      USA                          https://www.lamp-lab.org/   \n",
       "59      USA                           http://www.mat.ucsb.edu/   \n",
       "60      USA                https://musicdynamicslab.uconn.edu/   \n",
       "\n",
       "                                        ContactPerson  \\\n",
       "0                  Richard Parncutt (founder/contact)   \n",
       "1   Andreas Rauber (group lead); Thomas Lidy (coll...   \n",
       "2   Michele Calella (Head); Anja‑Xiaoxing Cui (Dep...   \n",
       "3                Gerhard Widmer (Head); Markus Schedl   \n",
       "4       Pieter-Jan Maes (Director & Head of Research)   \n",
       "..                                                ...   \n",
       "56      David Temperley (contact for Music Cognition)   \n",
       "57                            Timothy Q. Gentner (PI)   \n",
       "58                           Laura K. Getz (Director)   \n",
       "59  Program faculty include JoAnn Kuchera‑Morin (A...   \n",
       "60  Edward W. Large; Ji Chul Kim; staff and studen...   \n",
       "\n",
       "                                          ContactInfo  \\\n",
       "0                        richard.parncutt@uni-graz.at   \n",
       "1                             rauber@ifs.tuwien.ac.at   \n",
       "2                      musikwissenschaft@univie.ac.at   \n",
       "3   https://www.jku.at/en/institute-of-computation...   \n",
       "4   https://www.ugent.be/lw/kunstwetenschappen/ipe...   \n",
       "..                                                ...   \n",
       "56                        temperley@esm.rochester.edu   \n",
       "57  tgentner@ucsd.edu; Phone: +1 858‑822‑6763; McG...   \n",
       "58           usdlamplab@gmail.com; lgetz@sandiego.edu   \n",
       "59  MAT program: info@mat.ucsb.edu; Address: 3309 ...   \n",
       "60  See lab site; affiliated EEG lab: https://csse...   \n",
       "\n",
       "                                            Specifics  \\\n",
       "0   systematic musicology; music cognition; empiri...   \n",
       "1   music information retrieval; audio feature ext...   \n",
       "2   systematic musicology; musicology; acoustics/p...   \n",
       "3   machine learning for music, expressive perform...   \n",
       "4   embodied music cognition, XR, interaction, mov...   \n",
       "..                                                ...   \n",
       "56  music perception; music cognition; music theor...   \n",
       "57  auditory neuroethology; animal communication; ...   \n",
       "58  music & speech perception; language and memory...   \n",
       "59  media arts; electronic music; visualization; V...   \n",
       "60  neural dynamics; rhythm/meter; entrainment; em...   \n",
       "\n",
       "                                              Sources  \\\n",
       "0                              https://zsm.kug.ac.at/   \n",
       "1   https://informatics.tuwien.ac.at/people/andrea...   \n",
       "2   https://ufind.univie.ac.at/en/pvz_sub.html?id=442   \n",
       "3   https://www.jku.at/en/institute-of-computation...   \n",
       "4   https://www.ugent.be/lw/kunstwetenschappen/ipe...   \n",
       "..                                                ...   \n",
       "56  https://www.esm.rochester.edu/theory/ea/music-...   \n",
       "57  https://gentnerlab.ucsd.edu/; https://psycholo...   \n",
       "58  https://www.lamp-lab.org/; https://www.sandieg...   \n",
       "59  https://www.mat.ucsb.edu/mad/; https://www.gra...   \n",
       "60                https://musicdynamicslab.uconn.edu/   \n",
       "\n",
       "                                                Notes  \\\n",
       "0   Centre existed 2009–2023 (archival site still ...   \n",
       "1   Group within Information Systems Engineering (...   \n",
       "2   Systematic Musicology is one of the department...   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "..                                                ...   \n",
       "56                                                NaN   \n",
       "57                                                NaN   \n",
       "58                                                NaN   \n",
       "59                                                NaN   \n",
       "60                                                NaN   \n",
       "\n",
       "                                    __source_file   Latitude  Longitude  \\\n",
       "0   music_research_labs_batch_2025-11-12_1333.csv  47.070868  15.438279   \n",
       "1   music_research_labs_batch_2025-11-12_1333.csv  48.208354  16.372504   \n",
       "2   music_research_labs_batch_2025-11-12_1333.csv  48.208354  16.372504   \n",
       "3                  music_cognition_labs_part1.csv  48.305908  14.286198   \n",
       "4                  music_cognition_labs_part1.csv  51.053829   3.725012   \n",
       "..                                            ...        ...        ...   \n",
       "56      Batch__US_Labs__Vanderbilt___Eastman_.csv        NaN        NaN   \n",
       "57      Batch__US_Labs__Vanderbilt___Eastman_.csv        NaN        NaN   \n",
       "58      music_cognition_research_batch_CAN_US.csv        NaN        NaN   \n",
       "59      Batch__US_Labs__Vanderbilt___Eastman_.csv        NaN        NaN   \n",
       "60      Batch__US_Labs__Vanderbilt___Eastman_.csv        NaN        NaN   \n",
       "\n",
       "                                             Keywords  \n",
       "0                            Computational Musicology  \n",
       "1   Human–Computer Interaction (Music); Music & AI...  \n",
       "2   Audio Signal Processing; Computational Musicology  \n",
       "3   Audio Signal Processing; Music Information Ret...  \n",
       "4   Auditory Cognition; Human–Computer Interaction...  \n",
       "..                                                ...  \n",
       "56                                   Music Perception  \n",
       "57                             Cognitive Neuroscience  \n",
       "58                             Cognitive Neuroscience  \n",
       "59  Audio Signal Processing; Human–Computer Intera...  \n",
       "60                             Cognitive Neuroscience  \n",
       "\n",
       "[61 rows x 14 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ----- Your canonical categories -----\n",
    "canonical = [\n",
    "    \"Music Information Retrieval (MIR)\",\n",
    "    \"Music & AI / Machine Learning\",\n",
    "    \"Computational Musicology\",\n",
    "    \"Audio Signal Processing\",\n",
    "    \"Auditory Cognition\",\n",
    "    \"Music Perception\",\n",
    "    \"Music Emotion & Affective Science\",\n",
    "    \"Memory & Learning\",\n",
    "    \"Development & Expertise\",\n",
    "    \"Music Neuroscience\",\n",
    "    \"Cognitive Neuroscience\",\n",
    "    \"Music & Health / Therapy\",\n",
    "    \"Performance Science\",\n",
    "    \"Human–Computer Interaction (Music)\",\n",
    "    \"Music Technology & Engineering\",\n",
    "    \"Cross-Cultural Music Cognition\",\n",
    "    \"Education & Pedagogy\",\n",
    "]\n",
    "\n",
    "# ----- Mapping from token → canonical category -----\n",
    "# IMPORTANT: these keys must be LOWERCASE and refer to INDIVIDUAL CONCEPTS\n",
    "token_map = {\n",
    "    # MIR\n",
    "    \"mir\": \"Music Information Retrieval (MIR)\",\n",
    "    \"music information retrieval\": \"Music Information Retrieval (MIR)\",\n",
    "    \"information retrieval\": \"Music Information Retrieval (MIR)\",\n",
    "\n",
    "    # AI/ML\n",
    "    \"machine learning\": \"Music & AI / Machine Learning\",\n",
    "    \"deep learning\": \"Music & AI / Machine Learning\",\n",
    "    \"creative ai\": \"Music & AI / Machine Learning\",\n",
    "    \"ai & music\": \"Music & AI / Machine Learning\",\n",
    "    \"ai/music\": \"Music & AI / Machine Learning\",\n",
    "    \"generative systems\": \"Music & AI / Machine Learning\",\n",
    "    \"machine listening\": \"Music & AI / Machine Learning\",\n",
    "    \"automatic music generation\": \"Music & AI / Machine Learning\",\n",
    "\n",
    "    # Computational musicology\n",
    "    \"systematic musicology\": \"Computational Musicology\",\n",
    "    \"empirical musicology\": \"Computational Musicology\",\n",
    "    \"computational musicology\": \"Computational Musicology\",\n",
    "    \"digital musicology\": \"Computational Musicology\",\n",
    "    \"corpus analysis\": \"Computational Musicology\",\n",
    "    \"corpus-based analysis\": \"Computational Musicology\",\n",
    "    \"computational music theory\": \"Computational Musicology\",\n",
    "\n",
    "    # Audio signal processing\n",
    "    \"audio signal processing\": \"Audio Signal Processing\",\n",
    "    \"audio processing\": \"Audio Signal Processing\",\n",
    "    \"audio engineering\": \"Audio Signal Processing\",\n",
    "    \"spatial audio\": \"Audio Signal Processing\",\n",
    "    \"room acoustics\": \"Audio Signal Processing\",\n",
    "    \"acoustics\": \"Audio Signal Processing\",\n",
    "    \"binaural\": \"Audio Signal Processing\",\n",
    "    \"ambisonics\": \"Audio Signal Processing\",\n",
    "\n",
    "    # Auditory cognition\n",
    "    \"hearing science\": \"Auditory Cognition\",\n",
    "    \"psychoacoustics\": \"Auditory Cognition\",\n",
    "    \"auditory perception\": \"Auditory Cognition\",\n",
    "    \"auditory illusions\": \"Auditory Cognition\",\n",
    "\n",
    "    # Music perception\n",
    "    \"music perception\": \"Music Perception\",\n",
    "    \"melodic perception\": \"Music Perception\",\n",
    "    \"rhythm perception\": \"Music Perception\",\n",
    "    \"beat perception\": \"Music Perception\",\n",
    "    \"tonality\": \"Music Perception\",\n",
    "    \"musical structure\": \"Music Perception\",\n",
    "\n",
    "    # Emotion\n",
    "    \"music & emotion\": \"Music Emotion & Affective Science\",\n",
    "    \"affective computing\": \"Music Emotion & Affective Science\",\n",
    "    \"affective responses\": \"Music Emotion & Affective Science\",\n",
    "    \"empirical aesthetics\": \"Music Emotion & Affective Science\",\n",
    "\n",
    "    # Memory / learning\n",
    "    \"memory for music\": \"Memory & Learning\",\n",
    "    \"music-evoked memory\": \"Memory & Learning\",\n",
    "\n",
    "    # Development / expertise\n",
    "    \"development\": \"Development & Expertise\",\n",
    "    \"developmental\": \"Development & Expertise\",\n",
    "    \"aging\": \"Development & Expertise\",\n",
    "    \"music training\": \"Development & Expertise\",\n",
    "\n",
    "    # Music neuroscience\n",
    "    \"music neuroscience\": \"Music Neuroscience\",\n",
    "    \"neuroscience of music\": \"Music Neuroscience\",\n",
    "    \"auditory neuroscience\": \"Music Neuroscience\",\n",
    "\n",
    "    # Cognitive neuroscience\n",
    "    \"cognitive neuroscience\": \"Cognitive Neuroscience\",\n",
    "    \"neural dynamics\": \"Cognitive Neuroscience\",\n",
    "    \"neural coding\": \"Cognitive Neuroscience\",\n",
    "    \"brain imaging\": \"Cognitive Neuroscience\",\n",
    "    \"neuroimaging\": \"Cognitive Neuroscience\",\n",
    "\n",
    "    # Health / therapy\n",
    "    \"music therapy\": \"Music & Health / Therapy\",\n",
    "    \"neurologic music therapy\": \"Music & Health / Therapy\",\n",
    "    \"health & wellbeing\": \"Music & Health / Therapy\",\n",
    "    \"clinical applications\": \"Music & Health / Therapy\",\n",
    "\n",
    "    # Performance science\n",
    "    \"expressive performance\": \"Performance Science\",\n",
    "    \"live performance\": \"Performance Science\",\n",
    "    \"performance science\": \"Performance Science\",\n",
    "\n",
    "    # HCI / interfaces\n",
    "    \"hci\": \"Human–Computer Interaction (Music)\",\n",
    "    \"interfaces\": \"Human–Computer Interaction (Music)\",\n",
    "    \"musical interfaces\": \"Human–Computer Interaction (Music)\",\n",
    "    \"interactive systems\": \"Human–Computer Interaction (Music)\",\n",
    "    \"xr\": \"Human–Computer Interaction (Music)\",\n",
    "    \"vr\": \"Human–Computer Interaction (Music)\",\n",
    "\n",
    "    # Music technology\n",
    "    \"audio technology\": \"Music Technology & Engineering\",\n",
    "    \"sound synthesis\": \"Music Technology & Engineering\",\n",
    "    \"electroacoustic music\": \"Music Technology & Engineering\",\n",
    "\n",
    "    # Education\n",
    "    \"education\": \"Education & Pedagogy\",\n",
    "    \"pedagogy\": \"Education & Pedagogy\",\n",
    "}\n",
    "\n",
    "# ----- Helper: split → normalize → map → dedupe → reassemble -----\n",
    "def clean_keywords(cell):\n",
    "    if pd.isna(cell):\n",
    "        return \"\"\n",
    "\n",
    "    # 1. split on semicolon, comma, slash\n",
    "    tokens = re.split(r\"[;,/]\", str(cell))\n",
    "\n",
    "    out = []\n",
    "    for t in tokens:\n",
    "        t_clean = t.strip().lower()\n",
    "\n",
    "        # map if recognized\n",
    "        if t_clean in token_map:\n",
    "            out.append(token_map[t_clean])\n",
    "\n",
    "    # dedupe\n",
    "    out = sorted(set(out))\n",
    "\n",
    "    # join back\n",
    "    return \"; \".join(out)\n",
    "\n",
    "df[\"Focus Keywords Cleaned\"] = df[\"Focus Keywords\"].apply(clean_keywords)\n",
    "\n",
    "df.rename(columns={\"Lab Name\":\"LabName\", \"Focus Keywords Cleaned\":\"Keywords\", \"Focus Keywords\":\"Specifics\", \"Leads\":\"ContactPerson\", \"Contact\":\"ContactInfo\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4157aae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/mir_labs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "84799efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geocoding: Espoo (Helsinki metro), Finland\n",
      "Geocoding: London, United Kingdom\n",
      "Geocoding: Plymouth, United Kingdom\n",
      "Geocoding: Sheffield, United Kingdom\n",
      "Geocoding: Southampton, United Kingdom\n",
      "Geocoding: York, United Kingdom\n",
      "Geocoding: Cambridge, United Kingdom\n",
      "Geocoding: Durham, United Kingdom\n",
      "Geocoding: London, United Kingdom\n",
      "Geocoding: London, United Kingdom\n",
      "Geocoding: Atlanta, GA, USA\n",
      "Geocoding: Berkeley, CA, USA\n",
      "Geocoding: Cambridge, MA, USA\n",
      "Geocoding: Davis, CA, USA\n",
      "Geocoding: New York, NY, USA\n",
      "Geocoding: Princeton, NJ, USA\n",
      "Geocoding: Stanford, CA, USA\n",
      "Geocoding: Columbus, OH, USA\n",
      "Geocoding: Evanston, IL, USA\n",
      "Geocoding: Los Angeles, CA, USA\n",
      "Geocoding: Medford, MA, USA\n",
      "Geocoding: Nashville, TN, USA\n",
      "Geocoding: New York, NY, USA\n",
      "Geocoding: Rochester, NY, USA\n",
      "Geocoding: Rochester, NY, USA\n",
      "Geocoding: San Diego, CA, USA\n",
      "Geocoding: San Diego, CA, USA\n",
      "Geocoding: Santa Barbara, CA, USA\n",
      "Geocoding: Storrs, CT, USA\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lab Name</th>\n",
       "      <th>Institution</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Website</th>\n",
       "      <th>Leads</th>\n",
       "      <th>Contact</th>\n",
       "      <th>Focus Keywords</th>\n",
       "      <th>Sources</th>\n",
       "      <th>Notes</th>\n",
       "      <th>__source_file</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Focus Keywords Cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Centre for Systematic Musicology (ZSM)</td>\n",
       "      <td>University of Graz</td>\n",
       "      <td>Graz</td>\n",
       "      <td>Austria</td>\n",
       "      <td>https://zsm.kug.ac.at/</td>\n",
       "      <td>Richard Parncutt (founder/contact)</td>\n",
       "      <td>richard.parncutt@uni-graz.at</td>\n",
       "      <td>systematic musicology; music cognition; empiri...</td>\n",
       "      <td>https://zsm.kug.ac.at/</td>\n",
       "      <td>Centre existed 2009–2023 (archival site still ...</td>\n",
       "      <td>music_research_labs_batch_2025-11-12_1333.csv</td>\n",
       "      <td>47.070868</td>\n",
       "      <td>15.438279</td>\n",
       "      <td>Computational Musicology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MIR Group @ TU Wien (Information &amp; Software En...</td>\n",
       "      <td>TU Wien</td>\n",
       "      <td>Vienna</td>\n",
       "      <td>Austria</td>\n",
       "      <td>https://www.ifs.tuwien.ac.at/mir/</td>\n",
       "      <td>Andreas Rauber (group lead); Thomas Lidy (coll...</td>\n",
       "      <td>rauber@ifs.tuwien.ac.at</td>\n",
       "      <td>music information retrieval; audio feature ext...</td>\n",
       "      <td>https://informatics.tuwien.ac.at/people/andrea...</td>\n",
       "      <td>Group within Information Systems Engineering (...</td>\n",
       "      <td>music_research_labs_batch_2025-11-12_1333.csv</td>\n",
       "      <td>48.208354</td>\n",
       "      <td>16.372504</td>\n",
       "      <td>Human–Computer Interaction (Music); Music &amp; AI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Systematic Musicology (Department of Musicology)</td>\n",
       "      <td>University of Vienna</td>\n",
       "      <td>Vienna</td>\n",
       "      <td>Austria</td>\n",
       "      <td>https://musikwissenschaft.univie.ac.at/</td>\n",
       "      <td>Michele Calella (Head); Anja‑Xiaoxing Cui (Dep...</td>\n",
       "      <td>musikwissenschaft@univie.ac.at</td>\n",
       "      <td>systematic musicology; musicology; acoustics/p...</td>\n",
       "      <td>https://ufind.univie.ac.at/en/pvz_sub.html?id=442</td>\n",
       "      <td>Systematic Musicology is one of the department...</td>\n",
       "      <td>music_research_labs_batch_2025-11-12_1333.csv</td>\n",
       "      <td>48.208354</td>\n",
       "      <td>16.372504</td>\n",
       "      <td>Audio Signal Processing; Computational Musicology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Institute of Computational Perception (ICP)</td>\n",
       "      <td>Johannes Kepler University Linz</td>\n",
       "      <td>Linz</td>\n",
       "      <td>Austria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gerhard Widmer (Head); Markus Schedl</td>\n",
       "      <td>https://www.jku.at/en/institute-of-computation...</td>\n",
       "      <td>machine learning for music, expressive perform...</td>\n",
       "      <td>https://www.jku.at/en/institute-of-computation...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>music_cognition_labs_part1.csv</td>\n",
       "      <td>48.305908</td>\n",
       "      <td>14.286198</td>\n",
       "      <td>Audio Signal Processing; Music Information Ret...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IPEM – Institute for Psychoacoustics &amp; Electro...</td>\n",
       "      <td>Ghent University</td>\n",
       "      <td>Ghent</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pieter-Jan Maes (Director &amp; Head of Research)</td>\n",
       "      <td>https://www.ugent.be/lw/kunstwetenschappen/ipe...</td>\n",
       "      <td>embodied music cognition, XR, interaction, mov...</td>\n",
       "      <td>https://www.ugent.be/lw/kunstwetenschappen/ipe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>music_cognition_labs_part1.csv</td>\n",
       "      <td>51.053829</td>\n",
       "      <td>3.725012</td>\n",
       "      <td>Auditory Cognition; Human–Computer Interaction...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Lab Name  \\\n",
       "0             Centre for Systematic Musicology (ZSM)   \n",
       "1  MIR Group @ TU Wien (Information & Software En...   \n",
       "2   Systematic Musicology (Department of Musicology)   \n",
       "3        Institute of Computational Perception (ICP)   \n",
       "4  IPEM – Institute for Psychoacoustics & Electro...   \n",
       "\n",
       "                       Institution    City  Country  \\\n",
       "0               University of Graz    Graz  Austria   \n",
       "1                          TU Wien  Vienna  Austria   \n",
       "2             University of Vienna  Vienna  Austria   \n",
       "3  Johannes Kepler University Linz    Linz  Austria   \n",
       "4                 Ghent University   Ghent  Belgium   \n",
       "\n",
       "                                   Website  \\\n",
       "0                   https://zsm.kug.ac.at/   \n",
       "1        https://www.ifs.tuwien.ac.at/mir/   \n",
       "2  https://musikwissenschaft.univie.ac.at/   \n",
       "3                                      NaN   \n",
       "4                                      NaN   \n",
       "\n",
       "                                               Leads  \\\n",
       "0                 Richard Parncutt (founder/contact)   \n",
       "1  Andreas Rauber (group lead); Thomas Lidy (coll...   \n",
       "2  Michele Calella (Head); Anja‑Xiaoxing Cui (Dep...   \n",
       "3               Gerhard Widmer (Head); Markus Schedl   \n",
       "4      Pieter-Jan Maes (Director & Head of Research)   \n",
       "\n",
       "                                             Contact  \\\n",
       "0                       richard.parncutt@uni-graz.at   \n",
       "1                            rauber@ifs.tuwien.ac.at   \n",
       "2                     musikwissenschaft@univie.ac.at   \n",
       "3  https://www.jku.at/en/institute-of-computation...   \n",
       "4  https://www.ugent.be/lw/kunstwetenschappen/ipe...   \n",
       "\n",
       "                                      Focus Keywords  \\\n",
       "0  systematic musicology; music cognition; empiri...   \n",
       "1  music information retrieval; audio feature ext...   \n",
       "2  systematic musicology; musicology; acoustics/p...   \n",
       "3  machine learning for music, expressive perform...   \n",
       "4  embodied music cognition, XR, interaction, mov...   \n",
       "\n",
       "                                             Sources  \\\n",
       "0                             https://zsm.kug.ac.at/   \n",
       "1  https://informatics.tuwien.ac.at/people/andrea...   \n",
       "2  https://ufind.univie.ac.at/en/pvz_sub.html?id=442   \n",
       "3  https://www.jku.at/en/institute-of-computation...   \n",
       "4  https://www.ugent.be/lw/kunstwetenschappen/ipe...   \n",
       "\n",
       "                                               Notes  \\\n",
       "0  Centre existed 2009–2023 (archival site still ...   \n",
       "1  Group within Information Systems Engineering (...   \n",
       "2  Systematic Musicology is one of the department...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                   __source_file   Latitude  Longitude  \\\n",
       "0  music_research_labs_batch_2025-11-12_1333.csv  47.070868  15.438279   \n",
       "1  music_research_labs_batch_2025-11-12_1333.csv  48.208354  16.372504   \n",
       "2  music_research_labs_batch_2025-11-12_1333.csv  48.208354  16.372504   \n",
       "3                 music_cognition_labs_part1.csv  48.305908  14.286198   \n",
       "4                 music_cognition_labs_part1.csv  51.053829   3.725012   \n",
       "\n",
       "                              Focus Keywords Cleaned  \n",
       "0                           Computational Musicology  \n",
       "1  Human–Computer Interaction (Music); Music & AI...  \n",
       "2  Audio Signal Processing; Computational Musicology  \n",
       "3  Audio Signal Processing; Music Information Ret...  \n",
       "4  Auditory Cognition; Human–Computer Interaction...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.exc import GeocoderTimedOut, GeocoderUnavailable\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "\n",
    "# Load your CSV\n",
    "# Initialize geocoder\n",
    "geolocator = Nominatim(user_agent=\"mir-labs-geocoder\", timeout=10)\n",
    "\n",
    "# Rate limiter with retries and delay\n",
    "geocode = RateLimiter(\n",
    "    geolocator.geocode,\n",
    "    min_delay_seconds=1,\n",
    "    max_retries=3,\n",
    "    error_wait_seconds=2\n",
    ")\n",
    "\n",
    "def safe_geocode(query):\n",
    "    \"\"\"Return (lat, lon) or (None, None) on failure.\"\"\"\n",
    "    try:\n",
    "        location = geocode(query)\n",
    "        if location:\n",
    "            return location.latitude, location.longitude\n",
    "        else:\n",
    "            return None, None\n",
    "    except (GeocoderTimedOut, GeocoderUnavailable):\n",
    "        return None, None\n",
    "    except Exception:\n",
    "        return None, None\n",
    "\n",
    "# Only geocode missing rows\n",
    "if \"Latitude\" not in df.columns:\n",
    "    df[\"Latitude\"] = None\n",
    "if \"Longitude\" not in df.columns:\n",
    "    df[\"Longitude\"] = None\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    if pd.isna(row[\"Latitude\"]) or pd.isna(row[\"Longitude\"]):\n",
    "        query = f\"{row['City']}, {row['Country']}\"\n",
    "        print(f\"Geocoding: {query}\")\n",
    "        lat, lon = safe_geocode(query)\n",
    "        df.at[idx, \"Latitude\"] = lat\n",
    "        df.at[idx, \"Longitude\"] = lon\n",
    "        time.sleep(1)  # extra politeness\n",
    "\n",
    "# Save updated file\n",
    "df.to_csv(\"mir_labs_with_coords.csv\", index=False)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65ed77ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.read_csv('data/mir_labs_with_coords.csv')\n",
    "\n",
    "df_new.rename(columns={\"Focus Keywords\":\"Specifics\",\"Focus Keywords Cleaned\":\"Keywords\", \"Leads\":\"ContactPerson\",\"Contact\":\"ContactInfo\"}, inplace=True)\n",
    "\n",
    "df_new.head()\n",
    "df_new.to_csv(\"data/mir_labs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc1c41ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lab Name</th>\n",
       "      <th>Institution</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Website</th>\n",
       "      <th>ContactPerson</th>\n",
       "      <th>ContactInfo</th>\n",
       "      <th>Specifics</th>\n",
       "      <th>Sources</th>\n",
       "      <th>Notes</th>\n",
       "      <th>__source_file</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Centre for Systematic Musicology (ZSM)</td>\n",
       "      <td>University of Graz</td>\n",
       "      <td>Graz</td>\n",
       "      <td>Austria</td>\n",
       "      <td>https://zsm.kug.ac.at/</td>\n",
       "      <td>Richard Parncutt (founder/contact)</td>\n",
       "      <td>richard.parncutt@uni-graz.at</td>\n",
       "      <td>systematic musicology; music cognition; empiri...</td>\n",
       "      <td>https://zsm.kug.ac.at/</td>\n",
       "      <td>Centre existed 2009–2023 (archival site still ...</td>\n",
       "      <td>music_research_labs_batch_2025-11-12_1333.csv</td>\n",
       "      <td>47.070868</td>\n",
       "      <td>15.438279</td>\n",
       "      <td>Computational Musicology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MIR Group @ TU Wien (Information &amp; Software En...</td>\n",
       "      <td>TU Wien</td>\n",
       "      <td>Vienna</td>\n",
       "      <td>Austria</td>\n",
       "      <td>https://www.ifs.tuwien.ac.at/mir/</td>\n",
       "      <td>Andreas Rauber (group lead); Thomas Lidy (coll...</td>\n",
       "      <td>rauber@ifs.tuwien.ac.at</td>\n",
       "      <td>music information retrieval; audio feature ext...</td>\n",
       "      <td>https://informatics.tuwien.ac.at/people/andrea...</td>\n",
       "      <td>Group within Information Systems Engineering (...</td>\n",
       "      <td>music_research_labs_batch_2025-11-12_1333.csv</td>\n",
       "      <td>48.208354</td>\n",
       "      <td>16.372504</td>\n",
       "      <td>Human–Computer Interaction (Music); Music &amp; AI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Systematic Musicology (Department of Musicology)</td>\n",
       "      <td>University of Vienna</td>\n",
       "      <td>Vienna</td>\n",
       "      <td>Austria</td>\n",
       "      <td>https://musikwissenschaft.univie.ac.at/</td>\n",
       "      <td>Michele Calella (Head); Anja‑Xiaoxing Cui (Dep...</td>\n",
       "      <td>musikwissenschaft@univie.ac.at</td>\n",
       "      <td>systematic musicology; musicology; acoustics/p...</td>\n",
       "      <td>https://ufind.univie.ac.at/en/pvz_sub.html?id=442</td>\n",
       "      <td>Systematic Musicology is one of the department...</td>\n",
       "      <td>music_research_labs_batch_2025-11-12_1333.csv</td>\n",
       "      <td>48.208354</td>\n",
       "      <td>16.372504</td>\n",
       "      <td>Audio Signal Processing; Computational Musicology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Institute of Computational Perception (ICP)</td>\n",
       "      <td>Johannes Kepler University Linz</td>\n",
       "      <td>Linz</td>\n",
       "      <td>Austria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gerhard Widmer (Head); Markus Schedl</td>\n",
       "      <td>https://www.jku.at/en/institute-of-computation...</td>\n",
       "      <td>machine learning for music, expressive perform...</td>\n",
       "      <td>https://www.jku.at/en/institute-of-computation...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>music_cognition_labs_part1.csv</td>\n",
       "      <td>48.305908</td>\n",
       "      <td>14.286198</td>\n",
       "      <td>Audio Signal Processing; Music Information Ret...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IPEM – Institute for Psychoacoustics &amp; Electro...</td>\n",
       "      <td>Ghent University</td>\n",
       "      <td>Ghent</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pieter-Jan Maes (Director &amp; Head of Research)</td>\n",
       "      <td>https://www.ugent.be/lw/kunstwetenschappen/ipe...</td>\n",
       "      <td>embodied music cognition, XR, interaction, mov...</td>\n",
       "      <td>https://www.ugent.be/lw/kunstwetenschappen/ipe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>music_cognition_labs_part1.csv</td>\n",
       "      <td>51.053829</td>\n",
       "      <td>3.725012</td>\n",
       "      <td>Auditory Cognition; Human–Computer Interaction...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Lab Name  \\\n",
       "0             Centre for Systematic Musicology (ZSM)   \n",
       "1  MIR Group @ TU Wien (Information & Software En...   \n",
       "2   Systematic Musicology (Department of Musicology)   \n",
       "3        Institute of Computational Perception (ICP)   \n",
       "4  IPEM – Institute for Psychoacoustics & Electro...   \n",
       "\n",
       "                       Institution    City  Country  \\\n",
       "0               University of Graz    Graz  Austria   \n",
       "1                          TU Wien  Vienna  Austria   \n",
       "2             University of Vienna  Vienna  Austria   \n",
       "3  Johannes Kepler University Linz    Linz  Austria   \n",
       "4                 Ghent University   Ghent  Belgium   \n",
       "\n",
       "                                   Website  \\\n",
       "0                   https://zsm.kug.ac.at/   \n",
       "1        https://www.ifs.tuwien.ac.at/mir/   \n",
       "2  https://musikwissenschaft.univie.ac.at/   \n",
       "3                                      NaN   \n",
       "4                                      NaN   \n",
       "\n",
       "                                       ContactPerson  \\\n",
       "0                 Richard Parncutt (founder/contact)   \n",
       "1  Andreas Rauber (group lead); Thomas Lidy (coll...   \n",
       "2  Michele Calella (Head); Anja‑Xiaoxing Cui (Dep...   \n",
       "3               Gerhard Widmer (Head); Markus Schedl   \n",
       "4      Pieter-Jan Maes (Director & Head of Research)   \n",
       "\n",
       "                                         ContactInfo  \\\n",
       "0                       richard.parncutt@uni-graz.at   \n",
       "1                            rauber@ifs.tuwien.ac.at   \n",
       "2                     musikwissenschaft@univie.ac.at   \n",
       "3  https://www.jku.at/en/institute-of-computation...   \n",
       "4  https://www.ugent.be/lw/kunstwetenschappen/ipe...   \n",
       "\n",
       "                                           Specifics  \\\n",
       "0  systematic musicology; music cognition; empiri...   \n",
       "1  music information retrieval; audio feature ext...   \n",
       "2  systematic musicology; musicology; acoustics/p...   \n",
       "3  machine learning for music, expressive perform...   \n",
       "4  embodied music cognition, XR, interaction, mov...   \n",
       "\n",
       "                                             Sources  \\\n",
       "0                             https://zsm.kug.ac.at/   \n",
       "1  https://informatics.tuwien.ac.at/people/andrea...   \n",
       "2  https://ufind.univie.ac.at/en/pvz_sub.html?id=442   \n",
       "3  https://www.jku.at/en/institute-of-computation...   \n",
       "4  https://www.ugent.be/lw/kunstwetenschappen/ipe...   \n",
       "\n",
       "                                               Notes  \\\n",
       "0  Centre existed 2009–2023 (archival site still ...   \n",
       "1  Group within Information Systems Engineering (...   \n",
       "2  Systematic Musicology is one of the department...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                   __source_file   Latitude  Longitude  \\\n",
       "0  music_research_labs_batch_2025-11-12_1333.csv  47.070868  15.438279   \n",
       "1  music_research_labs_batch_2025-11-12_1333.csv  48.208354  16.372504   \n",
       "2  music_research_labs_batch_2025-11-12_1333.csv  48.208354  16.372504   \n",
       "3                 music_cognition_labs_part1.csv  48.305908  14.286198   \n",
       "4                 music_cognition_labs_part1.csv  51.053829   3.725012   \n",
       "\n",
       "                                            Keywords  \n",
       "0                           Computational Musicology  \n",
       "1  Human–Computer Interaction (Music); Music & AI...  \n",
       "2  Audio Signal Processing; Computational Musicology  \n",
       "3  Audio Signal Processing; Music Information Ret...  \n",
       "4  Auditory Cognition; Human–Computer Interaction...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"data/mir_labs.csv\")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f22be54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Computational Musicology',\n",
       "       'Human–Computer Interaction (Music); Music & AI / Machine Learning; Music Information Retrieval (MIR)',\n",
       "       'Audio Signal Processing; Computational Musicology',\n",
       "       'Audio Signal Processing; Music Information Retrieval (MIR); Performance Science',\n",
       "       'Auditory Cognition; Human–Computer Interaction (Music)',\n",
       "       'Audio Signal Processing; Auditory Cognition; Music & Health / Therapy',\n",
       "       'Memory & Learning; Music Perception', nan,\n",
       "       'Auditory Cognition; Cognitive Neuroscience',\n",
       "       'Audio Signal Processing; Music Information Retrieval (MIR)',\n",
       "       'Music & AI / Machine Learning; Music Emotion & Affective Science',\n",
       "       'Music & Health / Therapy', 'Auditory Cognition; Music Perception',\n",
       "       'Auditory Cognition; Music & Health / Therapy; Music Emotion & Affective Science',\n",
       "       'Audio Signal Processing; Music Technology & Engineering',\n",
       "       'Audio Signal Processing; Auditory Cognition; Computational Musicology',\n",
       "       'Audio Signal Processing',\n",
       "       'Cognitive Neuroscience; Music & Health / Therapy; Music Neuroscience',\n",
       "       'Audio Signal Processing; Computational Musicology; Human–Computer Interaction (Music); Music & AI / Machine Learning; Music Information Retrieval (MIR)',\n",
       "       'Cognitive Neuroscience',\n",
       "       'Education & Pedagogy; Music Information Retrieval (MIR)',\n",
       "       'Audio Signal Processing; Human–Computer Interaction (Music); Music Technology & Engineering',\n",
       "       'Music Emotion & Affective Science',\n",
       "       'Human–Computer Interaction (Music)',\n",
       "       'Music Technology & Engineering',\n",
       "       'Development & Expertise; Music Perception',\n",
       "       'Audio Signal Processing; Music & AI / Machine Learning; Music Information Retrieval (MIR)',\n",
       "       'Human–Computer Interaction (Music); Performance Science',\n",
       "       'Audio Signal Processing; Auditory Cognition',\n",
       "       'Music & AI / Machine Learning',\n",
       "       'Education & Pedagogy; Music Neuroscience',\n",
       "       'Cognitive Neuroscience; Music Neuroscience',\n",
       "       'Music & AI / Machine Learning; Music Information Retrieval (MIR); Music Perception',\n",
       "       'Music Perception',\n",
       "       'Audio Signal Processing; Human–Computer Interaction (Music); Music Perception; Music Technology & Engineering',\n",
       "       'Development & Expertise; Music Neuroscience',\n",
       "       'Development & Expertise; Education & Pedagogy',\n",
       "       'Cognitive Neuroscience; Music Perception',\n",
       "       'Development & Expertise',\n",
       "       'Music & AI / Machine Learning; Music Information Retrieval (MIR)',\n",
       "       'Audio Signal Processing; Human–Computer Interaction (Music)'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new[\"Keywords\"].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "miros_web",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
